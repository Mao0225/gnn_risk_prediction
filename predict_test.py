import matplotlib
matplotlib.use('Agg', force=True)  # å¿…é¡»åœ¨æ‰€æœ‰å¯¼å…¥ä¹‹å‰

import os
import argparse
import pandas as pd
import numpy as np
import torch
from datetime import datetime
import subprocess
import sys

# æ¢å¤ Polygon å¯¼å…¥ï¼ˆç”¨äºå¤„ç†å‡ ä½•æ•°æ®æ„å»ºå›¾ç»“æ„ï¼Œéç»˜å›¾ï¼‰
from shapely.geometry import Polygon

from model import GNN
from utils import build_graph

def load_and_preprocess_data(file_path):
    """
    åŠ è½½å¹¶é¢„å¤„ç†Excelæ ¼å¼çš„åœ°ç†ç©ºé—´æ•°æ®
    åŒ…å«ä¸¥æ ¼çš„æ•°æ®æ ¡éªŒï¼Œç¡®ä¿å‡ ä½•æ•°æ®æœ‰æ•ˆæ€§ï¼Œé¿å…åç»­å¤„ç†å´©æºƒ
    """
    print(f"ğŸ”„ æ­£åœ¨åŠ è½½æ•°æ®: {file_path}")
    try:
        # åŠ è½½åŸå§‹æ•°æ®
        df = pd.read_excel(file_path)
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œå…± {len(df)} è¡Œ")

        # å®šä¹‰ç‰¹å¾åˆ—ï¼ˆç»Ÿä¸€ç®¡ç†ï¼Œé¿å…é‡å¤ä¹¦å†™ï¼‰
        FEATURE_COLS = [
            'å¹´å‡é™', 'åœŸå£¤æ¸—', 'äººå£å¯†', 'æš´é›¨å¤©', 'æ‘åº„åˆ†',
            'è€•åœ°å ', 'å¡åº¦', 'dem', 'åŒ»é™¢', 'å…¬å®‰',
            'æ²³ç½‘å¯†', 'è¡Œæ´ªèƒ½', 'å§”å æ¯”', 'å¼±å æ¯”',
            'å«å æ¯”', 'GDP1å æ¯”'
        ]

        # æ£€æŸ¥ç‰¹å¾åˆ—æ˜¯å¦å­˜åœ¨
        missing_features = [col for col in FEATURE_COLS if col not in df.columns]
        if missing_features:
            raise ValueError(f"âŒ æ•°æ®ä¸­ç¼ºå°‘å¿…è¦çš„ç‰¹å¾åˆ—: {', '.join(missing_features)}")

        # å¤„ç†å‡ ä½•æ•°æ®ï¼ˆå¤šé‡æ ¡éªŒï¼Œè¿‡æ»¤æ— æ•ˆåæ ‡ï¼‰
        print("ğŸ”„ å¤„ç†å‡ ä½•æ•°æ®...")
        if 'Object' not in df.columns:
            raise ValueError("âŒ æ•°æ®ä¸­ç¼ºå°‘'Object'åˆ—ï¼ˆå‡ ä½•åæ ‡æ•°æ®ï¼‰")

        coords = []
        valid_indices = []  # è®°å½•æœ‰æ•ˆæ•°æ®çš„åŸç´¢å¼•
        for idx, obj in enumerate(df['Object']):
            try:
                # 1. è·³è¿‡ç©ºå€¼/éå­—ç¬¦ä¸²æ ¼å¼
                if pd.isna(obj) or not isinstance(obj, str):
                    print(f"âš ï¸ è·³è¿‡ç©º/éå­—ç¬¦ä¸²åæ ‡ï¼ˆè¡Œ{idx}ï¼‰")
                    continue

                # 2. è§£æåæ ‡ï¼ˆæ•è·è¯­æ³•é”™è¯¯ï¼‰
                try:
                    coord = eval(obj)
                except (SyntaxError, NameError) as e:
                    print(f"âš ï¸ åæ ‡æ ¼å¼è§£æå¤±è´¥ï¼ˆè¡Œ{idx}ï¼‰: {str(e)}, æ•°æ®: {obj[:50]}...")
                    continue

                # 3. æ ¡éªŒåæ ‡åŸºæœ¬æ ¼å¼ï¼ˆå¿…é¡»æ˜¯éç©ºåˆ—è¡¨ï¼‰
                if not isinstance(coord, list) or len(coord) == 0:
                    print(f"âš ï¸ åæ ‡ä¸æ˜¯æœ‰æ•ˆåˆ—è¡¨ï¼ˆè¡Œ{idx}ï¼‰: {obj[:50]}...")
                    continue

                # 4. æå–å¤šè¾¹å½¢ç‚¹åˆ—è¡¨ï¼ˆå…¼å®¹åµŒå¥—æ ¼å¼ï¼‰
                polygon_points = coord[0] if (isinstance(coord[0], list) and
                                              all(isinstance(p, (list, tuple)) for p in coord[0])) else coord

                # 5. æ ¡éªŒå¤šè¾¹å½¢ç‚¹æ•°ï¼ˆè‡³å°‘3ä¸ªç‚¹æ‰èƒ½æ„æˆå¤šè¾¹å½¢ï¼‰
                if len(polygon_points) < 3:
                    print(f"âš ï¸ å¤šè¾¹å½¢ç‚¹æ•°ä¸è¶³3ä¸ªï¼ˆè¡Œ{idx}ï¼‰: å®é™…{len(polygon_points)}ä¸ªç‚¹")
                    continue

                # 6. æ ¡éªŒæ¯ä¸ªç‚¹æ˜¯å¦ä¸ºäºŒç»´æœ‰æ•ˆæ•°å­—
                valid_point = True
                for point in polygon_points:
                    if not isinstance(point, (list, tuple)) or len(point) != 2:
                        print(f"âš ï¸ æ— æ•ˆåæ ‡ç‚¹ï¼ˆè¡Œ{idx}ï¼‰: {point}")
                        valid_point = False
                        break
                    # æ ¡éªŒåæ ‡æ˜¯å¦ä¸ºæ•°å­—
                    try:
                        float(point[0])
                        float(point[1])
                    except (ValueError, TypeError):
                        print(f"âš ï¸ åæ ‡ä¸æ˜¯æœ‰æ•ˆæ•°å­—ï¼ˆè¡Œ{idx}ï¼‰: {point}")
                        valid_point = False
                        break

                if valid_point:
                    coords.append(coord)
                    valid_indices.append(idx)

            except Exception as e:
                print(f"âš ï¸ å¤„ç†åæ ‡æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼ˆè¡Œ{idx}ï¼‰: {str(e)}")
                continue

        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆåæ ‡
        if len(coords) == 0:
            raise ValueError("âŒ æ— ä»»ä½•æœ‰æ•ˆå‡ ä½•åæ ‡æ•°æ®ï¼Œæ— æ³•ç»§ç»­å¤„ç†")

        # ç­›é€‰æœ‰æ•ˆæ•°æ®è¡Œ
        df_valid = df.iloc[valid_indices].reset_index(drop=True)
        print(f"âœ… å·²ç­›é€‰å‡ºæœ‰æ•ˆæ•°æ® {len(df_valid)} è¡Œï¼ˆåŸå§‹æ•°æ® {len(df)} è¡Œï¼‰")

        # åˆ›å»ºæœ‰æ•ˆå¤šè¾¹å½¢ï¼ˆè¿‡æ»¤é¢ç§¯ä¸º0çš„æ— æ•ˆå¤šè¾¹å½¢ï¼‰
        try:
            polygons = []
            for coord in coords:
                poly_points = coord[0] if isinstance(coord[0], list) else coord
                poly = Polygon(poly_points)
                # è¿‡æ»¤é¢ç§¯æ¥è¿‘0çš„å¤šè¾¹å½¢ï¼ˆé¿å…åç»­å¤„ç†å´©æºƒï¼‰
                if poly.area > 1e-8:
                    polygons.append(poly)
            print(f"âœ… æˆåŠŸåˆ›å»º {len(polygons)} ä¸ªæœ‰æ•ˆå¤šè¾¹å½¢ï¼ˆè¿‡æ»¤æ— æ•ˆå¤šè¾¹å½¢ {len(coords)-len(polygons)} ä¸ªï¼‰")
        except Exception as e:
            raise ValueError(f"âŒ åˆ›å»ºå¤šè¾¹å½¢æ—¶å‡ºé”™: {str(e)}")

        # æå–åŒ¹é…çš„ç‰¹å¾æ•°æ®ï¼ˆç¡®ä¿ä¸æœ‰æ•ˆå¤šè¾¹å½¢æ•°é‡ä¸€è‡´ï¼‰
        features = df[FEATURE_COLS].iloc[valid_indices].values[:len(polygons)]
        print(f"âœ… æå–ç‰¹å¾æ•°æ®: {features.shape[0]}è¡Œ, {features.shape[1]}åˆ—")

        # å¤„ç†æ ‡ç­¾ï¼ˆç¡®ä¿ä¸æœ‰æ•ˆæ•°æ®åŒ¹é…ï¼‰
        labels = None
        if 'é£é™©å€¼' in df_valid.columns:
            labels = df_valid['é£é™©å€¼'].values[:len(polygons)]  # ä¸å¤šè¾¹å½¢æ•°é‡å¯¹é½
            print(f"âœ… å‘ç°çœŸå®æ ‡ç­¾ï¼Œå…± {len(labels)} ä¸ªï¼ˆä¸å¤šè¾¹å½¢æ•°é‡ä¸€è‡´ï¼‰")
        else:
            print("â„¹ï¸ æ•°æ®ä¸­æœªåŒ…å«'é£é™©å€¼'åˆ—ï¼Œä»…è¿›è¡Œé¢„æµ‹")

        # æ„å»ºå›¾ç»“æ„
        print("ğŸ”„ æ„å»ºå›¾ç»“æ„...")
        try:
            data = build_graph(polygons, features)
            print(f"âœ… å›¾æ„å»ºå®Œæˆï¼ŒèŠ‚ç‚¹æ•°: {data.x.shape[0]}, è¾¹æ•°: {data.edge_index.shape[1]}")
        except Exception as e:
            raise RuntimeError(f"âŒ æ„å»ºå›¾ç»“æ„å¤±è´¥: {str(e)}")

        # ç»‘å®šæ ‡ç­¾ï¼ˆç¡®ä¿æ•°é‡ä¸€è‡´ï¼‰
        if labels is not None:
            if len(labels) != data.x.shape[0]:
                raise ValueError(f"âŒ æ ‡ç­¾æ•°é‡ï¼ˆ{len(labels)}ï¼‰ä¸èŠ‚ç‚¹æ•°é‡ï¼ˆ{data.x.shape[0]}ï¼‰ä¸åŒ¹é…")
            data.y = torch.tensor(labels, dtype=torch.float)

        return df_valid, data, polygons

    except Exception as e:
        print(f"âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥: {str(e)}")
        raise  # å‘ä¸Šå±‚æŠ›å‡ºå¼‚å¸¸ï¼Œä¾¿äºå®šä½é—®é¢˜


def predict(file_path, model_path, base_out_dir):
    print("ğŸš€ å¼€å§‹é¢„æµ‹æµç¨‹...")
    # 1. åˆ›å»ºè¾“å‡ºç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    exp_dir = os.path.join(base_out_dir, f"predict_{timestamp}")
    os.makedirs(exp_dir, exist_ok=True)
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {exp_dir}")

    try:
        # 2. åŠ è½½æ•°æ®ï¼ˆå·²åšä¸¥æ ¼æ ¡éªŒï¼‰
        df_valid, data, polygons = load_and_preprocess_data(file_path)

        # 3. åŠ è½½æ¨¡å‹
        print(f"ğŸ”„ åŠ è½½æ¨¡å‹: {model_path}")
        model = GNN(in_channels=data.x.shape[1], hidden_channels=128)
        # å…¼å®¹PyTorch 2.0+ï¼Œé¿å…å®‰å…¨è­¦å‘Š
        model.load_state_dict(torch.load(model_path, map_location="cpu", weights_only=True))
        model.eval()
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")

        # 4. é¢„æµ‹ï¼ˆå»é™¤å¤šä½™ç»´åº¦ï¼Œç¡®ä¿ä¸æ•°æ®åŒ¹é…ï¼‰
        print("ğŸ”„ å¼€å§‹é¢„æµ‹...")
        with torch.no_grad():
            preds = model(data).numpy().squeeze()  # æŒ¤å‹å¤šä½™ç»´åº¦
        print(f"âœ… é¢„æµ‹å®Œæˆï¼Œé¢„æµ‹å€¼èŒƒå›´: {preds.min():.3f} - {preds.max():.3f}")

        # ç¡®ä¿é¢„æµ‹å€¼ä¸æœ‰æ•ˆæ•°æ®æ•°é‡ä¸€è‡´
        if len(preds) != len(df_valid):
            print(f"âš ï¸ é¢„æµ‹å€¼æ•°é‡({len(preds)})ä¸æœ‰æ•ˆæ•°æ®è¡Œæ•°({len(df_valid)})ä¸åŒ¹é…ï¼Œå°†æˆªæ–­/è¡¥å…¨")
            preds = preds[:len(df_valid)] if len(preds) > len(df_valid) else np.pad(preds, (0, len(df_valid)-len(preds)))

        # 5. ä¿å­˜ç»“æœ
        df_result = df_valid.copy()




        df_result["é¢„æµ‹é£é™©å€¼"] = preds
        if "é£é™©å€¼" in df_result.columns:
            df_result["å·®å€¼"] = df_result["é£é™©å€¼"] - df_result["é¢„æµ‹é£é™©å€¼"]
            df_result["ç»å¯¹å·®å€¼"] = np.abs(df_result["å·®å€¼"])

        excel_path = os.path.join(exp_dir, "predict_results.xlsx")
        df_result.to_excel(excel_path, index=False)
        print(f"âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {excel_path}")
        # ğŸ”„ è°ƒç”¨ç‹¬ç«‹ç»˜å›¾è„šæœ¬ (é¿å…å’Œ torch å†²çª)
        try:
            subprocess.run(
                [sys.executable, "predict_plot.py", excel_path, exp_dir],
                check=True
            )
            print("âœ… å¯è§†åŒ–å›¾è¡¨å·²ç”Ÿæˆ")
        except Exception as e:
            print(f"âš ï¸ ç»˜å›¾å¤±è´¥: {e}")

        # 6. è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ˆä»…å½“æœ‰çœŸå®æ ‡ç­¾æ—¶ï¼‰
        if "é£é™©å€¼" in df_result.columns:
            true_values = df_result["é£é™©å€¼"].values
            mse = np.mean((true_values - preds) ** 2)
            mae = np.mean(np.abs(true_values - preds))
            rmse = np.sqrt(mse)
            # é¿å…RÂ²è®¡ç®—æ—¶åˆ†æ¯ä¸º0
            ss_total = np.sum((true_values - np.mean(true_values)) ** 2)
            r2 = 1 - np.sum((true_values - preds) ** 2) / ss_total if ss_total != 0 else 0.0

            print("ğŸ“Š è¯„ä¼°æŒ‡æ ‡:")
            print(f"   MSE:  {mse:.4f}")
            print(f"   MAE:  {mae:.4f}")
            print(f"   RMSE: {rmse:.4f}")
            print(f"   RÂ²:   {r2:.4f}")

            # ä¿å­˜æŒ‡æ ‡
            metrics_df = pd.DataFrame([{"MSE": mse, "MAE": mae, "RMSE": rmse, "R2": r2}])
            metrics_path = os.path.join(exp_dir, "metrics.xlsx")
            metrics_df.to_excel(metrics_path, index=False)
            print(f"ğŸ“Š æŒ‡æ ‡å·²ä¿å­˜åˆ°: {metrics_path}")

        # 7. åˆ—å‡ºç”Ÿæˆçš„æ–‡ä»¶
        print("\nğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶:")
        files = sorted(os.listdir(exp_dir))
        if not files:
            print("   âš ï¸ æœªç”Ÿæˆä»»ä½•æ–‡ä»¶")
        else:
            for file in files:
                file_path = os.path.join(exp_dir, file)
                if os.path.isfile(file_path):
                    size = os.path.getsize(file_path)
                    print(f"   ğŸ“„ {file} ({size} bytes)")

        print(f"\nğŸ‰ é¢„æµ‹å®Œæˆ! æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {exp_dir}")

    except Exception as e:
        print(f"âŒ é¢„æµ‹è¿‡ç¨‹å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()  # è¾“å‡ºå®Œæ•´é”™è¯¯æ ˆ


if __name__ == "__main__":
    print("ğŸ”¥ ç¨‹åºå¯åŠ¨...")

    try:
        parser = argparse.ArgumentParser(description="GNNé£é™©å€¼é¢„æµ‹å·¥å…·")
        parser.add_argument("--data", type=str, help="è¾“å…¥Excelæ•°æ®æ–‡ä»¶è·¯å¾„", default="data/test.xlsx")
        parser.add_argument("--model", type=str, default="models/best_model.pth", help="è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„")
        parser.add_argument("--out", type=str, default="results/predict", help="è¾“å‡ºç›®å½•")
        args = parser.parse_args()

        print(f"   å‚æ•°:")
        print(f"   æ•°æ®æ–‡ä»¶: {args.data}")
        print(f"   æ¨¡å‹æ–‡ä»¶: {args.model}")
        print(f"   è¾“å‡ºç›®å½•: {args.out}")

        # éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§
        if not os.path.exists(args.data):
            print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
            exit(1)
        if not os.path.exists(args.model):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model}")
            exit(1)

        # æ‰§è¡Œé¢„æµ‹
        predict(args.data, args.model, args.out)

    except Exception as e:
        print(f"ğŸ’¥ ç¨‹åºå¼‚å¸¸ç»ˆæ­¢: {str(e)}")
        import traceback
        traceback.print_exc()
        exit(1)